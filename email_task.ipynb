{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6ZQK1sCZS4o",
        "outputId": "3a115d91-b257-452f-e32d-5a4570e8906a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: click in c:\\users\\5a_traders\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\5a_traders\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\5a_traders\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\5a_traders\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
            "   --------------------------- ------------ 1.0/1.5 MB 5.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.5/1.5 MB 5.0 MB/s eta 0:00:00\n",
            "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
            "Installing collected packages: regex, nltk\n",
            "Successfully installed nltk-3.9.1 regex-2024.11.6\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d7RX3zK2ZTgj"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5scj6SpcFav",
        "outputId": "3522bb82-2b46-48f9-8700-c60572cc3282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\5A_Traders\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\5A_Traders\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\5A_Traders\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\5A_Traders\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     C:\\Users\\5A_Traders\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download NLTK resources for NLP\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y--1xARRZmT0",
        "outputId": "86f7ab12-35dc-4f66-b2ff-3ab0adfcff77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing sample emails...\n",
            "Processing email from manager@example.com: Team Meeting and Tasks\n",
            "Processing email from projectlead@example.com: Deadline Reminder\n",
            "Processing email from hr@example.com: New Assignments\n",
            "Processing email from client@example.com: Urgent: Task Update Required\n",
            "Processing email from team@example.com: Weekly Summary\n",
            "Tasks saved to tasks.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Sample email data for demonstration\n",
        "sample_emails = [\n",
        "    {\n",
        "        \"subject\": \"Team Meeting and Tasks\",\n",
        "        \"from\": \"manager@example.com\",\n",
        "        \"body\": \"Please complete the presentation by Monday and finalize the budget report by Friday. Ensure all team tasks are updated.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Deadline Reminder\",\n",
        "        \"from\": \"projectlead@example.com\",\n",
        "        \"body\": \"Donâ€™t forget the submission deadline for the project is next Wednesday. Coordinate with the design team.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"New Assignments\",\n",
        "        \"from\": \"hr@example.com\",\n",
        "        \"body\": \"You have been assigned new tasks. Please review the onboarding documents and schedule training sessions.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Urgent: Task Update Required\",\n",
        "        \"from\": \"client@example.com\",\n",
        "        \"body\": \"We need an update on the website redesign. Provide a timeline for the next steps by tomorrow.\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Weekly Summary\",\n",
        "        \"from\": \"team@example.com\",\n",
        "        \"body\": \"Summarize the weekly progress and prepare a report for the upcoming review meeting.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Function to extract tasks from email body\n",
        "# def extract_tasks(email_body):\n",
        "#     sentences = nltk.sent_tokenize(email_body)\n",
        "#     tasks = []\n",
        "#     for sentence in sentences:\n",
        "#         words = nltk.word_tokenize(sentence)\n",
        "#         tagged = nltk.pos_tag(words)\n",
        "#         if \"task\" in sentence.lower() or \"deadline\" in sentence.lower():\n",
        "#             tasks.append(sentence)\n",
        "#     return tasks\n",
        "\n",
        "\n",
        "def extract_tasks(email_body):\n",
        "    # Define broader keywords\n",
        "    task_keywords = [\"task\", \"deadline\", \"update\", \"prepare\", \"provide\", \"submit\", \"review\"]\n",
        "    sentences = nltk.sent_tokenize(email_body)\n",
        "    tasks = []\n",
        "    for sentence in sentences:\n",
        "        if any(keyword in sentence.lower() for keyword in task_keywords):\n",
        "            tasks.append(sentence)\n",
        "    return tasks\n",
        "\n",
        "\n",
        "# Save tasks to a local JSON file\n",
        "def save_tasks_to_file(tasks, file_name=\"tasks.json\"):\n",
        "    try:\n",
        "        with open(file_name, \"w\") as f:\n",
        "            json.dump(tasks, f, indent=4)\n",
        "        print(f\"Tasks saved to {file_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving tasks: {e}\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Process sample emails\n",
        "    print(\"Processing sample emails...\")\n",
        "    all_tasks = []\n",
        "    for email_data in sample_emails:\n",
        "        print(f\"Processing email from {email_data['from']}: {email_data['subject']}\")\n",
        "        tasks = extract_tasks(email_data['body'])\n",
        "        for task in tasks:\n",
        "            all_tasks.append({\n",
        "                \"task\": task,\n",
        "                \"email_subject\": email_data['subject'],\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            })\n",
        "\n",
        "    # Save tasks\n",
        "    if all_tasks:\n",
        "        save_tasks_to_file(all_tasks)\n",
        "    else:\n",
        "        print(\"No tasks found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xrs82WcVb0ta"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
